{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4230ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from spacy.cli import download\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3026bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import matutils, models, corpora, similarities\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355c5760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "download('en_core_web_sm')\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "tokenizer=ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7686e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "picklefile=open('stack_dataframe_cleaned-1','rb')\n",
    "stack_df=pickle.load(picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8da3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>id_1</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>display_name</th>\n",
       "      <th>...</th>\n",
       "      <th>views</th>\n",
       "      <th>answer_body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>owner_user_id_1</th>\n",
       "      <th>new_body</th>\n",
       "      <th>qa</th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_unlink</th>\n",
       "      <th>list_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17050</td>\n",
       "      <td>1635517</td>\n",
       "      <td>267</td>\n",
       "      <td>395451</td>\n",
       "      <td>How to download a file over http with authoriz...</td>\n",
       "      <td>&lt;p&gt;I have a script that I'd like to continue u...</td>\n",
       "      <td>267</td>\n",
       "      <td>python|python-3.x|urllib</td>\n",
       "      <td>19629</td>\n",
       "      <td>Lasse V. Karlsen</td>\n",
       "      <td>...</td>\n",
       "      <td>41691</td>\n",
       "      <td>&lt;p&gt;Direct from the Py3k docs: &lt;a href=\"http://...</td>\n",
       "      <td>395451</td>\n",
       "      <td>37522.0</td>\n",
       "      <td>I have a script that I'd like to continue usin...</td>\n",
       "      <td>How to download a file over http with authoriz...</td>\n",
       "      <td>[download, file, authorization, python, workin...</td>\n",
       "      <td>Direct from the Py3k docs: http://docs.python....</td>\n",
       "      <td>direct py3k docs</td>\n",
       "      <td>[python, python-3.x, urllib]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35281</td>\n",
       "      <td>3345402</td>\n",
       "      <td>2225682</td>\n",
       "      <td>19009932</td>\n",
       "      <td>Import arbitrary python source file. (Python 3...</td>\n",
       "      <td>&lt;p&gt;How can I import an arbitrary python source...</td>\n",
       "      <td>2225682</td>\n",
       "      <td>python|python-3.x|python-3.3</td>\n",
       "      <td>39887</td>\n",
       "      <td>falsetru</td>\n",
       "      <td>...</td>\n",
       "      <td>18449</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;&lt;code&gt;importlib&lt;/code&gt; helper funct...</td>\n",
       "      <td>19009932</td>\n",
       "      <td>895245.0</td>\n",
       "      <td>How can I import an arbitrary python source fi...</td>\n",
       "      <td>Import arbitrary python source file. (Python 3...</td>\n",
       "      <td>[import, arbitrary, python, source, file, pyth...</td>\n",
       "      <td>helper function\\nHere is a convenient, ready-...</td>\n",
       "      <td>helper function convenient ready use helper re...</td>\n",
       "      <td>[python, python-3.x, python-3.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52323</td>\n",
       "      <td>4936459</td>\n",
       "      <td>298479</td>\n",
       "      <td>9039333</td>\n",
       "      <td>How to run an inline shell script from python?</td>\n",
       "      <td>&lt;p&gt;I have a small shell script in a string ins...</td>\n",
       "      <td>298479</td>\n",
       "      <td>python|bash</td>\n",
       "      <td>2476</td>\n",
       "      <td>ThiefMaster</td>\n",
       "      <td>...</td>\n",
       "      <td>39117</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;import subprocess\\n\\nscript = \"\"\"\\n...</td>\n",
       "      <td>9039333</td>\n",
       "      <td>17160.0</td>\n",
       "      <td>I have a small shell script in a string inside...</td>\n",
       "      <td>How to run an inline shell script from python?...</td>\n",
       "      <td>[run, inline, shell, script, python, small, sh...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[python, bash]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0    index       id      id_1  \\\n",
       "0    17050  1635517      267    395451   \n",
       "3    35281  3345402  2225682  19009932   \n",
       "7    52323  4936459   298479   9039333   \n",
       "\n",
       "                                               title  \\\n",
       "0  How to download a file over http with authoriz...   \n",
       "3  Import arbitrary python source file. (Python 3...   \n",
       "7     How to run an inline shell script from python?   \n",
       "\n",
       "                                                body  owner_user_id  \\\n",
       "0  <p>I have a script that I'd like to continue u...            267   \n",
       "3  <p>How can I import an arbitrary python source...        2225682   \n",
       "7  <p>I have a small shell script in a string ins...         298479   \n",
       "\n",
       "                           tags  view_count      display_name  ...  views  \\\n",
       "0      python|python-3.x|urllib       19629  Lasse V. Karlsen  ...  41691   \n",
       "3  python|python-3.x|python-3.3       39887          falsetru  ...  18449   \n",
       "7                   python|bash        2476       ThiefMaster  ...  39117   \n",
       "\n",
       "                                         answer_body parent_id  \\\n",
       "0  <p>Direct from the Py3k docs: <a href=\"http://...    395451   \n",
       "3  <p><strong><code>importlib</code> helper funct...  19009932   \n",
       "7  <pre><code>import subprocess\\n\\nscript = \"\"\"\\n...   9039333   \n",
       "\n",
       "   owner_user_id_1                                           new_body  \\\n",
       "0          37522.0  I have a script that I'd like to continue usin...   \n",
       "3         895245.0  How can I import an arbitrary python source fi...   \n",
       "7          17160.0  I have a small shell script in a string inside...   \n",
       "\n",
       "                                                  qa  \\\n",
       "0  How to download a file over http with authoriz...   \n",
       "3  Import arbitrary python source file. (Python 3...   \n",
       "7  How to run an inline shell script from python?...   \n",
       "\n",
       "                                                text  \\\n",
       "0  [download, file, authorization, python, workin...   \n",
       "3  [import, arbitrary, python, source, file, pyth...   \n",
       "7  [run, inline, shell, script, python, small, sh...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Direct from the Py3k docs: http://docs.python....   \n",
       "3   helper function\\nHere is a convenient, ready-...   \n",
       "7                                                      \n",
       "\n",
       "                                       answer_unlink  \\\n",
       "0                                   direct py3k docs   \n",
       "3  helper function convenient ready use helper re...   \n",
       "7                                                      \n",
       "\n",
       "                          list_tags  \n",
       "0      [python, python-3.x, urllib]  \n",
       "3  [python, python-3.x, python-3.3]  \n",
       "7                    [python, bash]  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_topics=20'#min_df originally 10\n",
    "tf_vect=CountVectorizer(max_df=0.8, min_df=5, stop_words='english',token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "#max_features=1000, \n",
    "tf=tf_vect.fit_transform(stack_df['qa']).toarray()\n",
    "tf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=stack_df['text']\n",
    "y=stack_df['list_tags'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24af75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(analyzer='word', max_df=.9,min_df=0.01,tokenizer=None,\n",
    "                    preprocessor=' '.join,stop_words=None,lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899c4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X)\n",
    "X_tfidf=vect.fit_transform(X).toarray()\n",
    "#print(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eaaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    #return pd.DataFrame.from_dict(topic_dict,orient='index')\n",
    "    return pd.DataFrame(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=display_topics(lda, tf_vect.get_feature_names_out(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce42fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbaf37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bba820",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(topics['Topic 0 weights'],y=topics['Topic 0 words'])\n",
    "plt.scatter(topics['Topic 1 weights'],y=topics['Topic 1 words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce873c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "picklefile=open('tsne_2dim_count','rb')\n",
    "tsne_features1=pickle.load(picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf028f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(k,num_points=100):\n",
    "    np.random.seed(9)\n",
    "    data = []\n",
    "    for i in range(0,k):\n",
    "        for _ in range(0,num_points):\n",
    "            data.append([tsne_features[:,0],tsne_features[:,1]])\n",
    "    x1,y1 = zip(*data)\n",
    "    #plt.xlabel('X')\n",
    "    #plt.ylabel('Y')\n",
    "    #plt.scatter(x1,y1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19962af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(6)\n",
    "x,y = zip(*data)\n",
    "plt.scatter(x, y, s=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "#X, _ = make_blobs(n_samples=10000, centers=centers, cluster_std=0.6)\n",
    "x,y = zip(*data)\n",
    "plt.scatter(x,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate bandwidth \n",
    "# as mentioned in module, bigger window would allow for smoother groupings, \n",
    "# We can think of the bandwidth as our kernel's radius, \n",
    "bandwidth = estimate_bandwidth(X, n_samples=500)\n",
    "print('bandwidth: %d' % bandwidth)\n",
    "\n",
    "#ms = MeanShift(bandwidth=bandwidth,bin_seeding=True)\n",
    "ms = MeanShift(bin_seeding=True)   # in the case where we do not define any parameters\n",
    "ms.fit(X)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne_features5=model.fit_transform(stack_df[['reputation','view_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from office hours nlp_pipline-ipynb\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)\n",
    "#try to play around with less topics top 5 words, top 6 words\n",
    "no_top_words = 30\n",
    "topic_df=display_topics(lda, vect.get_feature_names_out(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/explaining-dbscan-clustering-18eaf5c83b31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6bcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-count vect-tfidf\n",
    "X_scale = StandardScaler().fit(tf).transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98674dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scale_count=pd.DataFrame(X_scale,columns=tf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scale_count.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d\n",
    "pca=PCA(n_components=2,random_state=42)\n",
    "pca.fit(df_scale_count)\n",
    "variance=pca.explained_variance_ratio_\n",
    "reduced_features=pca.fit_transform(X_tfidf)\n",
    "var=np.cumsum(np.round(variance,3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad955e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(0,20)\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "sum_of_squared_distances=[]\n",
    "K=range(2,50)\n",
    "for k in K:\n",
    "    km=KMeans(n_clusters=k,max_iter=200,n_init=10)\n",
    "    km=km.fit(X_tfidf)\n",
    "    sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fa38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K,sum_of_squared_distances,'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ea878",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k=30\n",
    "model=KMeans(n_clusters=true_k,init='k-means++',max_iter=200,n_init=10)\n",
    "model.fit(X_tfidf)\n",
    "labels=model.labels_\n",
    "topics_cl=pd.DataFrame(list(zip(stack_df['qa'],labels)),columns=['topic','cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topics_cl.sort_values(by=['cluster']))\n",
    "topic_sort=topics_cl.sort_values(by=['cluster'])\n",
    "topic_sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sort.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_cluster_center=pca.transform(model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "#z=gaussian_kde(reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50044d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_cluster_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(reduced_features[:,0], reduced_features[:,1], c=model.predict(X_tfidf))\n",
    "plt.scatter(reduced_cluster_center[:, 0], reduced_cluster_center[:,1], marker='x', s=150, c='b')\n",
    "plt.xlabel('PCA_component 1 Python')\n",
    "plt.ylabel('PCA_component 2 Miscellaneous Python')\n",
    "plt.title('Cluster Centers from reduced dimension of the TFIDF Matrix ')\n",
    "plt.savefig(f'Cluster centers from reduced dimension of tfidf matrix.jpg',bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b4fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(reduced_features[:,0], reduced_features[:,1], c=model.predict(X_tfidf),alpha=0.2)\n",
    "plt.xlabel('PCA_component 1 Python')\n",
    "plt.ylabel('PCA_component 2 Miscellaneous Python')\n",
    "plt.title('Scatter plot of reduced dimension of the TFIDF Matrix ')\n",
    "plt.savefig(f'Scatter plot of reduced dimension of the TFIDF Matrix.jpg',bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score(labels,model.predict(X_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(X_tfidf,labels=model.predict(X_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d913b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "result={'cluster':labels,'topic':stack_df['qa']}\n",
    "result=pd.DataFrame(result)\n",
    "for k in range(0,true_k):\n",
    "   s=result[result.cluster==k]\n",
    "   text=s['topic'].str.cat(sep=' ')\n",
    "   text=text.lower()\n",
    "   text=' '.join([word for word in text.split()])\n",
    "   wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "   print('Cluster: {}'.format(k))\n",
    "   print('Titles')\n",
    "   titles=topics_cl[topics_cl.cluster==k]['topic']         \n",
    "   #print(titles.to_string(index=False))\n",
    "   plt.figure()\n",
    "   plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "   plt.axis(\"off\")\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e0d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
